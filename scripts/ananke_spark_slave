#!/bin/bash
export SPARK_HOME=/spark-2.2.1-bin-hadoop2.7
mkdir -p /home/hdfs/.ssh
chown hdfs /home/hdfs/.ssh
rm /home/hdfs/.ssh/authorized_keys
wget -O /home/hdfs/.ssh/authorized_keys http://$1:5000/id_rsa.pub
wget -O $HADOOP_HOME/etc/hadoop/core-site.xml http://$1:5000/core-site.xml 
chown hdfs $HADOOP_HOME/etc/hadoop/core-site.xml 
chown hdfs /home/hdfs/.ssh/authorized_keys
chmod 700 /home/hdfs/.ssh
chmod 600 home/hdfs/.ssh/authorized_keys
runuser -l hdfs -c 'eval `ssh-agent -s` && ssh-add'
/spark-2.2.1-bin-hadoop2.7/bin/spark-class org.apache.spark.deploy.worker.Worker -i $2 -p $3 spark://$1:7077